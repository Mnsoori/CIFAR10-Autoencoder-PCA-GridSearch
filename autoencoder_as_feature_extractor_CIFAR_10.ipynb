{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder-as-feature-extractor-CIFAR-10.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNEB3a7WwDuc",
        "colab_type": "text"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi3n3xrDPOw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sys\n",
        "\n",
        "import keras\n",
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPool2D, Flatten, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPool1D, CuDNNLSTM, Reshape\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras.optimizers import SGD, Adam, RMSprop, Adadelta\n",
        "import keras.backend as K\n",
        "from keras.objectives import mean_squared_error\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, RobustScaler, StandardScaler\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liDxQg1_wYln",
        "colab_type": "text"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s1SdxRiPg9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2PvbGXgQL6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict = {0:'Airplane', 1:'Automobile', 2:'Bird', 3:'Cat', 4:'Deer', 5:'Dog', 6:'Frog', 7:'Horse', 8:'Ship', 9:'Truck'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRMpwDMTwdK0",
        "colab_type": "text"
      },
      "source": [
        "Mujtaba's Augmentation Cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W88Dp-zrH8Kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np                                \n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle\n",
        "#load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_rows, img_cols , channels= 32,32,3\n",
        "print('Original images examples')\n",
        "for i in range(0,9):\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    plt.imshow(x_train[i])\n",
        "plt.show()\n",
        "\n",
        "# Number of rows of the dataset\n",
        "number_of_rows = x_train.shape[0]\n",
        "\n",
        "# set up image augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.3,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# see example augmentation images\n",
        "print('Augmentated images examples')\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size = number_of_rows):\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].astype(np.uint8))\n",
        "    plt.show()\n",
        "    break\n",
        "\n",
        "# Combine original with augmentated\n",
        "x_train_aug = np.concatenate((x_train, X_batch.astype(np.uint8)), axis=0)\n",
        "y_train_aug = np.concatenate((y_train, y_batch.astype(np.uint8)), axis=0)\n",
        "\n",
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "x_train_aug = x_train_aug.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "y_train_aug = keras.utils.to_categorical(y_train_aug, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Select 10% randomly from training data\n",
        "new_size = int(number_of_rows*0.1)\n",
        "random_indices = np.random.choice(number_of_rows, size = new_size, replace=False)\n",
        "x_train_random = x_train[random_indices, :]\n",
        "y_train_random = y_train[random_indices, :]\n",
        "\n",
        "datagen.fit(x_train_random)\n",
        "\n",
        "# see example of randomly augmentation images\n",
        "print('Randomly augmentated images examples')\n",
        "for X_batch_random, y_batch_random in datagen.flow(x_train_random, y_train_random, batch_size=new_size):\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch_random[i].astype(np.uint8))\n",
        "    plt.show()\n",
        "    break\n",
        "\n",
        "# Combine original with augmentated\n",
        "x_train_random_aug = np.concatenate((x_train_random, X_batch_random.astype(np.uint8)), axis=0)\n",
        "y_train_random_aug = np.concatenate((y_train_random, y_batch_random.astype(np.uint8)), axis=0)\n",
        "\n",
        "x_train_random_aug = x_train_random_aug.astype('float32') / 255.\n",
        "\n",
        "y_train_random_aug = keras.utils.to_categorical(y_train_random_aug, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TonKQ86jwirf",
        "colab_type": "text"
      },
      "source": [
        "Creating imbalanced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPs0St3XQSlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' #use mujtaba's output instead later\n",
        "x_test_extra = []\n",
        "y_test_extra = []\n",
        "x_train_final = []\n",
        "y_train_final = []\n",
        "count = [0, 0, 0]\n",
        "for i, j in zip(x_train, y_train):\n",
        "    if (j==2):\n",
        "        if(count[0]<2000):\n",
        "            x_test_extra.append(i)\n",
        "            y_test_extra.append(j)\n",
        "            count[0]+=1\n",
        "        else:\n",
        "            x_train_final.append(i)\n",
        "            y_train_final.append(j)\n",
        "    elif (j==4):\n",
        "        if(count[1]<2000):\n",
        "            x_test_extra.append(i)\n",
        "            y_test_extra.append(j)\n",
        "            count[1]+=1\n",
        "        else:\n",
        "            x_train_final.append(i)\n",
        "            y_train_final.append(j)\n",
        "    elif (j==9):\n",
        "        if(count[2]<2000):\n",
        "            x_test_extra.append(i)\n",
        "            y_test_extra.append(j)\n",
        "            count[2]+=1\n",
        "        else:\n",
        "            x_train_final.append(i)\n",
        "            y_train_final.append(j)\n",
        "    else:\n",
        "        x_train_final.append(i)\n",
        "        y_train_final.append(j)\n",
        "        \n",
        "x_test_extra = np.array(x_test_extra)\n",
        "y_test_extra = np.array(y_test_extra)\n",
        "x_train_final = np.array(x_train_final)\n",
        "y_train_final = np.array(y_train_final) '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK7_7AIkQfKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' x_test_final = np.append(x_test_extra, x_test, axis=0)\n",
        "y_test_final = np.append(y_test_extra, y_test, axis=0) '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4eXqt92wtsT",
        "colab_type": "text"
      },
      "source": [
        "Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e3SrWY7Qjy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' x_train_final = x_train_final.astype('float32')\n",
        "x_test_final = x_test_final.astype('float32')\n",
        "x_train_final = x_train_final / 255\n",
        "x_test_final = x_test_final / 255 '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUearOGjw2VJ",
        "colab_type": "text"
      },
      "source": [
        "Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLMjZTHWQq4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train, x_valid, y_trainf, y_validf = train_test_split(x_train_random_aug, y_train_random_aug, test_size=0.2, random_state=42, shuffle= True)\n",
        "# x_train_random_aug -> x_train_final, y_train_random_aug -> y_train_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcsbpPd1xBH0",
        "colab_type": "text"
      },
      "source": [
        "Target conversion to categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAdg3zsuQvr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_trainf, 10)\n",
        "y_valid = keras.utils.to_categorical(y_validf, 10)\n",
        "y_test_one_hot = y_train_random_aug #keras.utils.to_categorical(y_train_random_aug, 10)\n",
        "# y_train_random_aug -> y_test_final "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgHzHui-xClX",
        "colab_type": "text"
      },
      "source": [
        "Necessary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6ab3Oi_Q0fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_block(input, chs): ## Convolution block of 2 layers\n",
        "    x = input\n",
        "    for i in range(2):\n",
        "        x = Conv2D(chs, 3, padding=\"same\")(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "##############################\n",
        "\n",
        "## Here, I compute the class weights for using in different models. \n",
        "## This is to order our model to emphasize more on classes with less training data.\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "               'balanced',\n",
        "                np.unique(y_trainf), \n",
        "                y_trainf.reshape(y_trainf.shape[0]))\n",
        "\n",
        "class_weights\n",
        "\n",
        "##############################\n",
        "\n",
        "def showOrigDec(orig, dec, num=10):  ## function used for visualizing original and reconstructed images of the autoencoder model\n",
        "    n = num\n",
        "    plt.figure(figsize=(20, 4))\n",
        "\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i+1)\n",
        "        plt.imshow(orig[300*i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i +1 + n)\n",
        "        plt.imshow(dec[300*i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()\n",
        "        \n",
        "def show_test(m, d):  ## function used for visualizing the predicted and true labels of test data\n",
        "    plt.figure(figsize =(40,8))\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(1, 5, i+1)\n",
        "        test_image = np.expand_dims(d[1810*i+5], axis=0)\n",
        "        test_result = m.predict(test_image)\n",
        "        plt.imshow(x_test_final[1810*i+5])\n",
        "        index = np.argsort(test_result[0,:])\n",
        "        plt.title(\"Pred:{}, True:{}\".format(dict[index[9]], dict[y_train_random_aug[1810*i+5][0]]))\n",
        "        # y_train_random_aug -> y_test_final\n",
        "    plt.show()\n",
        "    \n",
        "def report(predictions): ## function used for creating a classification report and confusion matrix\n",
        "    cm=confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
        "    print(\"Classification Report:\\n\")\n",
        "    cr=classification_report(y_test.argmax(axis=1),\n",
        "                                predictions.argmax(axis=1), \n",
        "                                target_names=list(dict.values()))\n",
        "    print(cr)\n",
        "    plt.figure(figsize=(12,12))\n",
        "    sns.heatmap(cm, annot=True, xticklabels = list(dict.values()), yticklabels = list(dict.values()), fmt=\"d\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsFQbpkixTO4",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5RnsDwpTsiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def general_ae():\n",
        "    input = Input((32,32,3))\n",
        "    \n",
        "    # Encoder\n",
        "    block1 = create_block(input, 32)\n",
        "    x = MaxPool2D(2)(block1)\n",
        "    block2 = create_block(x, 64)\n",
        "    \n",
        "    #Middle\n",
        "    x = MaxPool2D(2)(block2)\n",
        "    middle = create_block(x, 128)\n",
        "    \n",
        "    # Decoder\n",
        "    block3 = create_block(middle, 64)\n",
        "    up1 = UpSampling2D((2,2))(block3)\n",
        "    block4 = create_block(up1, 32)\n",
        "    up2 = UpSampling2D((2,2))(block4)\n",
        "    \n",
        "    # output\n",
        "    x = Conv2D(3, 1)(up2)\n",
        "    output = Activation(\"sigmoid\")(x)\n",
        "    return Model(input, middle), Model(input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItZEr3TGVGad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_ae(m):  ## function for Implementing general autoencoder\n",
        "    if m=='ae':\n",
        "        encoder, model = general_ae()\n",
        "        \n",
        "    return encoder, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx1Hmiw3VJ6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(y_true, y_pred):  ## loss function for using in autoencoder models\n",
        "    mses = mean_squared_error(y_true, y_pred)\n",
        "    return K.sum(mses, axis=(1,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPsPcgCPxbrv",
        "colab_type": "text"
      },
      "source": [
        "Implementing AE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-Hn1H6VYSqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_ae, model_ae = run_ae('ae')\n",
        "model_ae.compile(SGD(1e-3, 0.9), loss=loss_function)\n",
        "model_ae.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGpk5LEiYW9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\n",
        "lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\n",
        "callbacks = [er, lr]\n",
        "history = model_ae.fit(x_train, x_train, \n",
        "                       batch_size=512,\n",
        "                       epochs=100,\n",
        "                       verbose=1,\n",
        "                       validation_data=(x_valid, x_valid),\n",
        "                       shuffle=True, callbacks=callbacks,\n",
        "                       class_weight=class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ptqjR9gYd3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idCyMnE-YyhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recon_test_ae = model_ae.predict(x_test)\n",
        "recon_valid_ae = model_ae.predict(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7aCZI6Ea4jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "showOrigDec(x_valid, recon_valid_ae)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6WO_uTTa7j4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "showOrigDec(x_test, recon_test_ae)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOtOXc56xxv2",
        "colab_type": "text"
      },
      "source": [
        "Extracting bottleneck features to use as inputs in the classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMe2Di2WbAn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gist_train_ae = encoder_ae.predict(x_train)\n",
        "gist_valid_ae = encoder_ae.predict(x_valid)\n",
        "gist_test_ae = encoder_ae.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzdMXc13x3n3",
        "colab_type": "text"
      },
      "source": [
        "Classifier Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGGB64oYbHnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier_conv(inp):\n",
        "    input = Input((inp.shape[1], inp.shape[2], inp.shape[3]))\n",
        "    x = Conv2D(1024, 3, padding=\"same\")(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPool2D(2)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Conv2D(128, 3, padding=\"same\")(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPool2D(2)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.35)(x)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dropout(0.69)(x)\n",
        "    output = Dense(10, activation='softmax')(x)\n",
        "    return Model(input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DwMDq1zbNoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_cls(m, inp):  ## function for Implementing convolutional classifier model\n",
        "    if m=='conv':\n",
        "        classifier = classifier_conv(inp)\n",
        "        \n",
        "    return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um6jNwsrx-02",
        "colab_type": "text"
      },
      "source": [
        "Convolutional AE with convolutional NN as classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zgz5A8xbRY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_ae_conv = run_cls('conv', gist_train_ae)\n",
        "decoder_ae_conv.compile(loss='categorical_crossentropy',\n",
        "                        optimizer=Adadelta(),\n",
        "                        metrics=['accuracy'])\n",
        "decoder_ae_conv.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgEdVxvwbWaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "er = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\n",
        "lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\n",
        "callbacks = [er, lr]\n",
        "hist1 = decoder_ae_conv.fit(gist_train_ae, y_trainf, batch_size=512, epochs=100, \n",
        "                            validation_data = (gist_valid_ae, y_valid),\n",
        "                            shuffle=True, callbacks=callbacks,\n",
        "                            class_weight=class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZzkFieGbabR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(hist1.history['accuracy'])\n",
        "plt.plot(hist1.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnQMEH3FbslJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Test accuracy for AE_conv model= {}'.format(decoder_ae_conv.evaluate(gist_test_ae, y_test)[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEMYz_IQbtia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_test(decoder_ae_conv, gist_test_ae)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpyGeQA1bxnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = decoder_ae_conv.predict(gist_test_ae)\n",
        "report(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}